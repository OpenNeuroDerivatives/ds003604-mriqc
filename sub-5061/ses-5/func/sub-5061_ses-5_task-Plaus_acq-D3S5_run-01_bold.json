{
  "aor": 0.015306886792452828,
  "aqi": 0.010707036037735847,
  "bids_meta": {
    "AcquisitionMatrixPE": 128,
    "BandwidthPerPixelPhaseEncode": 22.645,
    "BaseResolution": 128,
    "BodyPartExamined": "BRAIN",
    "ConversionSoftware": "spm8",
    "DerivedVendorReportedEchoSpacing": 0.000689998,
    "DeviceSerialNumber": "45239",
    "DwellTime": 2.2e-06,
    "EchoTime": 0.03,
    "EchoTrainLength": 63,
    "EffectiveEchoSpacing": 0.000344999,
    "FlipAngle": 80,
    "ImageComments": "Unaliased_MB4_PE4",
    "ImageOrientationPatientDICOM": [
      1,
      0,
      0,
      0,
      1,
      0
    ],
    "ImageType": [
      "ORIGINAL",
      "PRIMARY",
      "M",
      "MB",
      "ND",
      "MOSAIC"
    ],
    "InPlanePhaseEncodingDirectionDICOM": "COL",
    "InstitutionAddress": "E_24th_St._100_Austin_Southmiddle_US_78712",
    "InstitutionName": "The_Univ._of_Texas_at_Austin_IRC",
    "InstitutionalDepartmentName": "IRC",
    "Instructions": "In this game you will hear a woman’s voice saying a sentence. I want you to answer the question 'Does the way she speaks make sense'. For example, 'Every day, she bakes one pie.' That makes sense, so you would say 'yes'. But if the way she speaks does not make sense, you will say 'no'. For example, 'Every day, she bakes one table.' That does not make sense, so you would say 'no'. Now we will try it on the computer. You will hear a sentence, and you have to decide 'does the way she speaks make sense?' If the answer is 'yes', please press the button under your index finger. If the answer is 'no', press the button under your middle finger. When you hear the shhh sound, press the button under your index finger for 'yes'. You will see a blue circle appear on the screen. When the circle changes to yellow, that is a reminder to go ahead and give your answer. If you aren’t sure, you can just take your best guess.",
    "MRAcquisitionType": "2D",
    "MagneticFieldStrength": 3,
    "Manufacturer": "Siemens",
    "ManufacturersModelName": "Skyra",
    "Modality": "MR",
    "MultibandAccelerationFactor": 4,
    "ParallelReductionFactorInPlane": 2,
    "PartialFourier": 1,
    "PatientPosition": "HFS",
    "PercentPhaseFOV": 100,
    "PhaseEncodingDirection": "j-",
    "PhaseEncodingSteps": 127,
    "PhaseResolution": 1,
    "PixelBandwidth": 1775,
    "ProcedureStepDescription": "Booth_Language",
    "ReceiveCoilName": "HeadNeck_64",
    "ReconMatrixPE": 128,
    "RefLinesPE": 100,
    "RepetitionTime": 1.25,
    "ScanOptions": "FS",
    "ScanningSequence": "EP",
    "SequenceName": "epfid2d1_128",
    "SequenceVariant": "SK_SS",
    "ShiftedAquisitionDate": "1815-03-14",
    "SliceThickness": 2,
    "SliceTiming": [
      0,
      0.263554322,
      0.527099883,
      0.790665888,
      1.054196846,
      0.087847547,
      0.351346379,
      0.614959112,
      0.878504673,
      1.142053154,
      0.175733061,
      0.439231893,
      0.702797897,
      0.966314252,
      0,
      0.263554322,
      0.527099883,
      0.790665888,
      1.054196846,
      0.087847547,
      0.351346379,
      0.614959112,
      0.878504673,
      1.142053154,
      0.175733061,
      0.439231893,
      0.702797897,
      0.966314252,
      0,
      0.263554322,
      0.527099883,
      0.790665888,
      1.054196846,
      0.087847547,
      0.351346379,
      0.614959112,
      0.878504673,
      1.142053154,
      0.175733061,
      0.439231893,
      0.702797897,
      0.966314252,
      0,
      0.263554322,
      0.527099883,
      0.790665888,
      1.054196846,
      0.087847547,
      0.351346379,
      0.614959112,
      0.878504673,
      1.142053154,
      0.175733061,
      0.439231893,
      0.702797897,
      0.966314252
    ],
    "SoftwareVersions": "syngo_MR_D13",
    "SpacingBetweenSlices": 2,
    "StationName": "AWP45239",
    "TaskDescription": "Participants were presented through earphones with one sentence at each trial. The task included three different experimental conditions: strongly congruent (SP_S), weakly congruent (SP_W) and incongruent (SP_I). The three sentence conditions in the semantic task were designed according to the following standards. The two congruent conditions were based on the association strength values between the verb and the object as defined in the University of South Florida Free Association Norms (Nelson et al. 2004). The strongly congruent condition had an association of 0.28-0.81 (M=0.41, SD=0.12) between the verb and the object in the sentence (e.g., SHE IS SINGING ONE SONG). The weakly congruent condition had an association of 0.02-0.19 (M=0.11, SD=0.05) between the verb and the object in the sentence (e.g., SHE DOES NOT TASTE TWO FOODS). In the incongruent condition, the verb and the object in the sentence had no semantic association (e.g., HE IS PLANTING THREE SHOES). In addition to the three experimental conditions, the task included a perceptual/motor control condition (SP_C) in which participants heard frequency modulated noise and were asked to press ‘yes’ whenever they heard the “sh-shh” sound. Participants completed two runs of the task with 10 trials per condition per run for a total of 20 stimuli for each of the four conditions. The task included a total number of 80 trials divided into two separate 40 trials runs titled task-Plaus_run-01 and task-Plaus_run-02. Stimuli duration ranged between 2748 and 4520 ms and was followed by an 1875 – 3450 ms jittered response interval. A blue circle appeared simultaneous to the auditory presentation of the stimuli, to help maintain attention in the task. The blue circle changed to yellow to provide an approximately 1000ms warning for the participants to respond, if they hadn’t already, before moving on to the next trial. Total trial duration ranged from 4694 to 7900 ms. Responses were recorded in two windows. Window 1 consisted of the first 750ms of the trial and window 2 begins after window 1 until the end of the trial.",
    "TaskName": "Plausability Task",
    "TotalReadoutTime": 0.0438149,
    "acq_id": "D3S5",
    "dataset": "ds003604",
    "modality": "bold",
    "run_id": 1,
    "session_id": "5",
    "subject_id": "5061",
    "task_id": "Plaus"
  },
  "dummy_trs": 0,
  "dvars_nstd": 63.92044239118484,
  "dvars_std": 1.3299518896682465,
  "dvars_vstd": 1.1622226242654028,
  "efc": 0.421863288098464,
  "fber": 1506.08251953125,
  "fd_mean": 0.361182271820094,
  "fd_num": 98,
  "fd_perc": 46.22641509433962,
  "fwhm_avg": 3.70156,
  "fwhm_x": 3.51837,
  "fwhm_y": 3.74822,
  "fwhm_z": 3.83809,
  "gcor": 0.0491174,
  "gsr_x": -0.01809084601700306,
  "gsr_y": 0.015587358735501766,
  "provenance": {
    "md5sum": "453b2db64d895a80e6fed512c14cdab4",
    "settings": {
      "fd_thres": 0.2,
      "testing": false
    },
    "software": "mriqc",
    "version": "22.0.6",
    "webapi_port": null,
    "webapi_url": "https://mriqc.nimh.nih.gov/api/v1"
  },
  "size_t": 212,
  "size_x": 128,
  "size_y": 128,
  "size_z": 56,
  "snr": 2.02159633394487,
  "spacing_tr": 1.25,
  "spacing_x": 2.0,
  "spacing_y": 2.0,
  "spacing_z": 2.0,
  "summary_bg_k": 92.66016238709199,
  "summary_bg_mad": 41.855550997641764,
  "summary_bg_mean": 322.46160888671875,
  "summary_bg_median": 196.66510009765625,
  "summary_bg_n": 677176.0,
  "summary_bg_p05": 162.4481201171875,
  "summary_bg_p95": 736.4870300292969,
  "summary_bg_stdv": 508.8214111328125,
  "summary_fg_k": 1.6864042832705914,
  "summary_fg_mad": 3052.4861272839407,
  "summary_fg_mean": 8721.939453125,
  "summary_fg_median": 7710.0634765625,
  "summary_fg_n": 139100.0,
  "summary_fg_p05": 4551.852099609375,
  "summary_fg_p95": 16552.238769531246,
  "summary_fg_stdv": 3813.83544921875,
  "tsnr": 25.168787486618385
}